# bdb-classifier

⚠️ WARNING: This project is under construction

## Project Overview
This project focuses on building machine learning models to classify raw audio recordings from a *Ball de Bot* dataset. The goal is to leverage advanced audio processing and classification techniques to analyze the unique traits of this traditional music style. By exploring three distinct classifier architectures, this project contributes to the intersection of cultural preservation and modern AI.

### What is Ball de Bot?

*Ball de Bot* (literally "dance of the jump") is a traditional folk music and dance genre from the Balearic Islands in Spain, more specifically Mallorca and Menorca. This vibrant tradition serves as a cornerstone of local cultural identity and is regularly performed during festivities and community gatherings.

The music of *Ball de Bot* typically features a blend of traditional instruments like the ximbomba (a friction drum), flabiol (a small fl te), and guitarró (a small guitar). Its vibrant and dynamic nature has made it a symbol of local identity and an integral part of festivities and community gatherings.

In the context of this project, the classification task involves identifying and categorizing the different subgenres within the *Ball de Bot* dataset, potentially aiding in cultural preservation. There are five different subgenres that can be identified: *bolero*, *jota*, *fandango mallorquí*, *fandango menorquí* and *mateixa*.

## Classifiers

### **First Approach**: Using DistilHuBERT for Audio Classification
For the initial classifier, a pretrained version of DistilHuBERT from the Hugging Face Transformers library was employed. DistilHuBERT is a distilled version of HuBERT (Hidden-Unit BERT), a model designed for self-supervised learning on audio data. It is particularly effective in extracting high-level representations from raw audio without requiring manual feature engineering.

**General overview:**

Raw audio data was normalized and segmented into suitable time frames. The model was fed with waveform inputs directly, eliminating the need for intermediate feature extraction like MFCCs.

DistilHuBERT, pretrained on large-scale audio datasets, provides robust feature representations by analyzing patterns such as intonation and rhythm.
The embeddings generated by the model were extracted and used as inputs for downstream classification.

Accuracy and other performance metrics were computed to evaluate how well DistilHuBERT could generalize to the unique characteristics of Ball de Bot audio.
Advantages of Using DistilHuBERT:
- **Efficiency**: The distilled architecture is smaller and faster while retaining high performance.
- **Feature Extraction**: This approach automatically captures complex and relevant audio features.
- **Transfer Learning**: Pretraining on diverse datasets allows the model to adapt effectively to domain-specific data with limited fine-tuning.

**Training process:**

<table>
  <tr>
    <td align="center">
        <img src="resources/classifier_distilhubert/W&B Chart 14_1_2025 23_29_45.png" alt="training_loss" width="400"/><br>
      <b>Image 1:</b> First image description.
    </td>
    <td align="center">
        <img src="resources/classifier_distilhubert/W&B Chart 14_1_2025 23_30_03.png" alt="eval_accuracy" width="400"/><br>
      <b>Image 2:</b> Second image description.
    </td>
  </tr>
</table>

**Evaluation process:**

<table>
  <tr>
    <td align="center">
        <img src="/home/snicolau/bdb-classifier/resources/classifier_distilhubert/conf_matrix.png" alt="eval_accuracy" width="350"/><br>
        <b>Image 3:</b> Second image description.
    </td>
  </tr>
</table>


The results indicate that the classifier effectively distinguishes the *bolero* class from the other classes. However, there is notable misclassification between the *fandango mallorquí* and *fandango menorquí* classes, which is expected due to their shared classification as fandangos, characterized by overlapping stylistic and musical attributes. Similarly, confusion between the *jota* and *mateixa* classes is observed, likely attributable to their closely related musical features and structural similarities.

### **Second Approach**: Audio feature extraction + Classical ML classifier

*Work in progress*

### **Third Approach**: Spectrogram extraction + CNN feature extraction + FC classifier

*Coming soon*